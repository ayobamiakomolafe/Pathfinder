{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX7bzDkZ9qEg"
      },
      "source": [
        "### **Data Extraction and Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eC3FcV4VltR"
      },
      "outputs": [],
      "source": [
        "# Function to Clean ATLAS Zipped file and save as dataframe (ensure to add .csv extension to save_cleaned_file_path e.g dir/cleaned.csv)\n",
        "def Clean_ATLAS(zipped_file_path, save_cleaned_file_path):\n",
        "  from zipfile import ZipFile\n",
        "  zf=ZipFile(zipped_file_path, 'r')\n",
        "  zf.extractall()\n",
        "  zf.close()\n",
        "\n",
        "  import pandas as pd\n",
        "  import seaborn as sns\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  df=pd.read_csv('/content/2023_06_15 atlas_antibiotics.csv')\n",
        "\n",
        "  new_list=[]\n",
        "  for i in range(df.shape[0]):\n",
        "    new_list.append(df.loc[i,'Amikacin': 'Meropenem vaborbactam_I'].dropna().to_dict())\n",
        "\n",
        "  df=df.loc[:, :'Phenotype']\n",
        "  df['Antibiotics']= new_list\n",
        "\n",
        "  big_list=[]\n",
        "  for i in range(df.shape[0]):\n",
        "    for row in df['Antibiotics'][i].keys():\n",
        "      if row.endswith('_I'):\n",
        "        x=row.split('_')[0]\n",
        "        big_list.append([i, x, df['Antibiotics'][i][row], df['Antibiotics'][i][x] ])\n",
        "\n",
        "  Antibiotics=pd.DataFrame(big_list)\n",
        "\n",
        "  clean_df=df.merge(Antibiotics, left_index=True, right_on=0, how='left').drop(['Antibiotics', 0], axis=1).rename(columns={1:\"Antibiotics\", 2:\"Status\", 3:\"COncentration\"})\n",
        "\n",
        "  clean_df.to_csv(save_cleaned_file_path, sep=',', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BVZLTXvJ3mO"
      },
      "outputs": [],
      "source": [
        "# Extract file from zipped file\n",
        "Clean_ATLAS('/content/drive/MyDrive/2023_06_15 atlas_antibiotics.zip', '/content/file.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hanNaZjE6MPr"
      },
      "source": [
        "### **Machine Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-yWz2FymrTs"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S2oEl-W6Aw_"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv('file.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XyqgfGMaVKp",
        "outputId": "7bf38e21-c496-42fb-de05-93d6a403dabd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9752774, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Check Dataset Shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pda6vsqq6zgK"
      },
      "outputs": [],
      "source": [
        "# Drop Unnecessary Columns\n",
        "df.drop(['Isolate Id','Study', 'State', 'Phenotype','COncentration'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeZYTY0SBFYE"
      },
      "outputs": [],
      "source": [
        "# Fill Missing Values\n",
        "df['Gender'].fillna('Male', inplace=True)\n",
        "df['In / Out Patient'].fillna('Inpatient', inplace=True)\n",
        "df['In / Out Patient']=df['In / Out Patient'].str.replace('None Given', 'Other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8box_twpxaWk"
      },
      "outputs": [],
      "source": [
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6VdF7jtoFYf"
      },
      "outputs": [],
      "source": [
        "# Rename column\n",
        "df.rename(columns={'In / Out Patient': 'Patient'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encode Categorical Columns\n",
        "\n",
        "cols=['Species', 'Family', 'Country', 'Gender', 'Age Group', 'Speciality',\n",
        "       'Source', 'Patient', 'Antibiotics']\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import pickle\n",
        "for i in cols:\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  df[i]=le.fit_transform(df[i])\n",
        "  name=i+'.pkl'\n",
        "  output = open(name, 'wb')\n",
        "  pickle.dump(le, output)\n",
        "  output.close()"
      ],
      "metadata": {
        "id": "I273ooc4r9NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPpTdzDDothH"
      },
      "outputs": [],
      "source": [
        "# Encode Target Columm\n",
        "\n",
        "df['Status'].replace('Susceptible', 0, inplace=True)\n",
        "df['Status'].replace('Resistant', 1, inplace=True)\n",
        "df['Status'].replace('Intermediate', 2, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUrJvb2sosAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba9fec5-99ab-4829-f41a-9fd4f36e37a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.487945 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 391\n",
            "[LightGBM] [Info] Number of data points in the train set: 6824657, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score -0.281570\n",
            "[LightGBM] [Info] Start training from score -1.682200\n",
            "[LightGBM] [Info] Start training from score -2.822834\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.835948392637718"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Light GBM Model\n",
        "\n",
        "X=df.drop('Status', axis=1)\n",
        "Y=df['Status']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.3, random_state=42)\n",
        "import lightgbm\n",
        "r= lightgbm.LGBMClassifier()\n",
        "r.fit(X_train, y_train)\n",
        "r.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "r.booster_.save_model('lgbr_base.txt')"
      ],
      "metadata": {
        "id": "6X56ZoMgJgLu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}